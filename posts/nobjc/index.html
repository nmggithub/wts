<!DOCTYPE html>
<html lang="en" prefix="og: https://ogp.me/ns#">

<head>
  <!-- -- Common -- -->
  <base target="_blank" />
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="no-referrer">
  <meta http-equiv="Content-Security-Policy" content="
      default-src 'none';
      style-src https://fonts.googleapis.com/ 'self';
      font-src https://fonts.gstatic.com/;
      img-src 'self';
      form-action 'none'
      " />
  <link rel="icon" href="/favicon.png" />
  <link rel="stylesheet" href="/style.css" />
  <!-- Site Name -->
  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "WebSite",
      "name": "Watch This Space",
      "url": "https://wts.dev/",
      "description": "A security research blog."
    }
  </script>
  <!-- Mastadon Attribution -->
  <meta name="fediverse:creator" content="@wtsdev@infosec.exchange">
  <!-- Twitter/X use the standard "name" attribute -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@wtsdev" />
  <meta name="twitter:creator" content="@wtsdev" />
  <!-- Facebook/OpenGraph use the non-standard "property" attribute -->
  <meta property="og:site_name" content="Watch This Space" />
  <meta property="og:image" content="https://wts.dev/favicon.png" />
  <meta property="og:image:secure_url" content="https://wts.dev/favicon.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="512" />
  <meta property="og:image:height" content="512" />
  <meta property="og:image:alt" content="A large purple letter W on a light tan background" />
  <!-- -- Page-Specific -- -->
  <!-- Styles -->
  <link rel="stylesheet" href="/post.css" />
  <!-- URL -->
  <link rel="canonical" href="https://wts.dev/posts/nobjc/" />
  <meta property="og:url" content="https://wts.dev/posts/nobjc/" />
  <!-- Title -->
  <meta name="og:title" content="I wrote an Objective-C bridge for Node.js. Don't use it. | Watch This Space" />
  <title>I wrote an Objective-C bridge for Node.js. Don't use it. | Watch This Space</title>
  <!-- Description -->
  <meta name="description" content="A security research blog." />
  <meta property="og:description" content="A security research blog." />
  <!-- Additional -->
  <meta property="og:type" content="article" />
  <!-- Author -->
  <meta property="article:author" content="https://github.com/nmggithub" />
  <meta name="author" content="Noah Gregory" />
  <!-- Keywords -->
  <meta name="keywords" content="security,macos,nodejs,objective-c,electron" />
  <meta property="article:tag" content="security,macos,nodejs,objective-c,electron" />
</head>

<body>
  <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
    <header>
      <h1 itemprop="headline">I wrote an Objective-C bridge for Node.js. Don't use it.</h1>
      <div id="about">
        <time itemprop="datePublished" datetime="2025-10-03">2025-10-03</time>
        <span>(updated <time itemprop="dateModified" datetime="2025-10-04">2025-10-04</time>)</span>
        <address itemprop="author" itemscope itemtype="https://schema.org/Person">by <a itemprop="email" title="Send me an email" href="mailto:noah@wts.dev"><span itemprop="name">Noah Gregory</span></a>
        </address>
      </div>
    </header>
    <h2>Clarification (<time datetime="2025-10-04">2025-10-04</time>)</h2>
    <p>In the below article I go pretty hard against FFI's in Node.js. To clarify, when I use that term in this article, I am mainly referring to <em>general-purpose</em> FFI's (those which allow calls to arbitrary foreign functions). Properly-scoped and limited bindings (wherein specifically-written functions, and <em>only</em> those functions, are callable) can be built and used relatively safely in Node.js (though, there's still inherent risk whenever involving native code). The main purpose of this article is to caution against the use of general-purpose FFI's in Node.js.</p>
    <h2>Introduction</h2>
    <p>I wrote a Node.js package that allows you to call Objective-C API's from Node.js. I do want to note that this is not an original idea of mine and there is prior work. <a href="https://github.com/TooTallNate">Nathan Rajlich</a> (former Node.js core contributor, now at Vercel) made <a href="https://github.com/TooTallNate/NodObjC">his own Node-Objective-C bridge, NodObjC,</a> years ago. His bridge is built on top of <a href="https://github.com/node-ffi/node-ffi">the now-long-dead <code><abbr title="foreign function interface">ffi</abbr></code> package</a> (<a href="https://github.com/node-ffi/node-ffi/commits?author=TooTallNate">which he also heavily contributed to</a>). I've (somewhat shamelessly) ripped off at least the name of his bridge. Mine is called <a href="https://github.com/nmggithub/nobjc"><b>nobjc.</b></a> But you shouldn't use it.</p>
    <h2>Why not use it?</h2>
    <p>Having a <b>foreign function interface</b> (FFI) in Node.js may sound like a great idea to some. The ability to call functions written in an entirely different language from JavaScript sounds like it would open up a wealth of opportunities for interoperability. While that may be true, it can also open up an enormous attack surface that the supposed benefits do not justify, primarily on desktop platforms. More specifically: <a href="https://www.electronjs.org/"><b>Electron.</b></a></p>
    <h3>FFI is bad on Electron</h3>
    <p>There's a reason why I chose to write my bridge specifically around Objective-C. The only practical (by some meaning of that word) use case for nobjc that I see is for use in macOS Electron applications (or similarly-desktop-targeting apps that are built on top of Node.js). But again: <em>don't use it for that.</em> As a security researcher who has dug deep into macOS's internals, I can say one thing fairly definitively: <b><em>many Electron apps on macOS are less secure against code injection than native apps.</em></b></p>
    <h2>Code injection and Electron</h2>
    <p>Electron allows developers to write desktop applications in JavaScript. Most times this JavaScript source code is shipped directly with the application and just sits on-disk, ready to be executed. What's worse is that this code is often executed without integrity checks, meaning that any malicious application also running on the user's computer (and which has write access to the code) can modify it and inject malware in the code.</p>
    <p>This type of code injection has happened. As early as 2019, <a href="https://www.bleepingcomputer.com/news/security/discord-turned-into-an-info-stealing-backdoor-by-new-malware/">a trojan dubbed <q><b>Spidey bot</b></q> was discovered modifying the JavaScript of the Discord client in an info-stealer attack.</a> Later stealers such as <a href="https://www.bleepingcomputer.com/news/security/discord-client-turned-into-a-password-stealer-by-updated-malware/"><b>AnarchyGrabber</b></a>, <a href="https://www.bleepingcomputer.com/news/security/discord-modified-to-steal-accounts-by-new-nitrohack-malware/"><b>NitroHack</b></a>, <a href="https://www.trendmicro.com/en_us/research/23/e/info-stealer-abusing-codespaces-puts-discord-users--data-at-risk.html"><b>PirateStealer</b></a>, and <a href="https://www.cyfirma.com/research/iluria-stealer-a-variant-of-another-discord-stealer/"><b>Iluria Stealer</b></a> have continued this trend of using code injection attacks on Discord. But Discord is not special here, and any Electron app can be vulnerable.</p>
    <h3 id="discord">Discord's stance on code injection</h3>
    <p>When I realized this attack vector in Discord, I reached out to their security team and received this response:</p>
    <blockquote>We do not consider physical/local attacks as valid security issues at this time. This stems from Chromium/Electron, the upstream software we use for our app, being vulnerable to this kind of attack. To read about why this is not considered as a vulnerability in their (and our) threat model you can check out <a href="https://chromium.googlesource.com/chromium/src/+/master/docs/security/faq.md#why-arent-physically_local-attacks-in-chromes-threat-model">https://chromium.googlesource.com/chromium/src/+/master/docs/security/faq.md#why-arent-physically_local-attacks-in-chromes-threat-model</a></blockquote>
    <p>The article Discord's team linked to, at the time of me writing this article, has this to say:</p>
    <blockquote>We consider these attacks outside Chrome's threat model, because there is no way for Chrome (or any application) to defend against a malicious user who has managed to log into your device as you, or who can run software with the privileges of your operating system user account. Such an attacker can modify executables and DLLs, change environment variables like PATH, change configuration files, read any data your user account owns, email it to themselves, and so on. Such an attacker has total control over your device, and nothing Chrome can do would provide a serious guarantee of defense. This problem is not special to Chrome ­— all applications must trust the physically-local user.</blockquote>
    <h3 id="code-injection-and-macos">Code injection and macOS</h3>
    <p>Now, if you are a Windows user (or someone who researches security on Windows) the above may seem like a fairly reasonable position to take. However, from my perspective as a macOS security researcher, the logic does not exactly hold for the macOS platform. Many of the things that the Chrome team calls out as things that malicious users (or apps) can do are not possible (or are severely restricted) on macOS.</p>
    <p>DLL hijacking is pretty much dead on macOS thanks to <a href="https://developer.apple.com/documentation/security/hardened-runtime">its <b>Hardened Runtime.</b></a> Also, executables cannot be easily modified and still work as expected due to Apple's fairly strict code-signing requirements. Overall, it's extremely difficult to get code injection on modern versions of Apple platforms, and now, with <a href="https://security.apple.com/blog/memory-integrity-enforcement/">Apple's introduction of <b>Memory Integrity Enforcement,</b></a> it's likely going to be even harder than it was before.</p>
    <p>But, if an Electron app on macOS makes use of JavaScript that's just sitting on disk in a place where other apps can access and potentially modify it (and does not perform integrity checks on the code before executing it), that leaves open a wide attack surface for code injection into the app. This is what I meant earlier when I said that many Electron apps are less secure against code injection than native apps.</p>
    <p>While <a href="https://developer.apple.com/documentation/security/app-sandbox">Apple's <b>App Sandbox</b></a> can provide filesystem containerization, I don't know of any Electron apps that utilize it for their JavaScript code. Electron apps that store their JavaScript code directly in their bundles may be better protected, as <a href="https://developer.apple.com/library/archive/documentation/Security/Conceptual/CodeSigningGuide/AboutCS/AboutCS.html">Apple's security features on macOS generally protect app bundles from outside tampering.</a> However, through my own testing, I have found this behavior to be inconsistent in practice.</p>
    <h2>What should be done</h2>
    <p>Throughout my research, I also reached out to Electron team about my concerns. I got a response from <a href="https://github.com/vertedinde">Keeley Hammond.</a> They informed me that Electron offers a feature called <a href="https://www.electronjs.org/docs/latest/tutorial/asar-integrity"><b>ASAR Integrity</b></a> which builds runtime integrity checks directly into applications to ensure that the JavaScript code on disk was not tampered with. While, obviously, no security solution is perfect, <a href="https://blog.trailofbits.com/2025/09/03/subverting-code-integrity-checks-to-locally-backdoor-signal-1password-slack-and-more/">the Electron team is actively patching bypasses to it.</a> I'd encourage all Electron developers to use this feature.</p>
    <h2>Why did I write nobjc?</h2>
    <p>And now, we circle back to nobjc. Why did I write it? There are many reasons, but I wrote it primarily as a proof-of-concept of what <em>not</em> to do with Node.js. The security of what you're developing should always be top of mind, and FFI's in desktop Node.js applications often pose far too much of a risk to be worth it. If you're considering using an FFI in your Electron application, please don't use mine. And please use ASAR Integrity. And, if you liked this article and want to see what I put out next: <a target="_self" href="/feed.xml">watch this space.</a></p>
  </article>
</body>

</html>